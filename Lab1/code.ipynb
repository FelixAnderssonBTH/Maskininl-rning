{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, log_loss\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''Reads the csv file and loads it into a pandas dataframe, then visualizes the first 5 rows of the dataframe'''\n",
    "\n",
    "wine_data = pd.read_csv('red.csv', delimiter=';')\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dropps the duplicates from the dataframe in order to avoid overfitting, then splits the data into the features and the target variable\n",
    "    The the data gets split into training and testing data using the train_test_split function from the sklearn library\n",
    "'''\n",
    "wine_data.drop_duplicates(inplace=True)\n",
    "\n",
    "X = wine_data.drop(columns=\"quality\")\n",
    "y = wine_data[\"quality\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "5    455\n",
      "6    423\n",
      "7    135\n",
      "4     51\n",
      "8     17\n",
      "3      6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "''' The data gets scaled using the StandardScaler from the sklearn library, then the data gets transformed using the fit_transform method\n",
    "    Then the values of the target variable are counted and printed in order to compare it with the balanced data in task 7'''\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Declair the two classifiers (Linear Discriminant Analysis and Random Forest) that will be used in the cross validation, then the cross validation is performed using the RepeatedKFold\n",
    "    function from the sklearn library, in order to determin the best classifier for the data. The results are stored in a dictionary.'''\n",
    "\n",
    "classifiers = {\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "cv = RepeatedKFold(n_splits=3, n_repeats=10, random_state=42)\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    scores = cross_val_score(clf, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "    results[name] = {\n",
    "        \"mean_accuracy\": np.mean(scores),\n",
    "        \"std_accuracy\": np.std(scores)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis:\n",
      "Mean Accuracy: 0.5640171174324866\n",
      "Standard Devation Accuracy: 0.02134683612095991 \n",
      "\n",
      "Random Forest:\n",
      "Mean Accuracy: 0.5861003302741122\n",
      "Standard Devation Accuracy: 0.021681168875144888 \n",
      "\n",
      "Best Classifier: Random Forest\n"
     ]
    }
   ],
   "source": [
    "'''visual representation of the results in order to compare the classifiers. also the best classifier is determined by comparing the mean accuracy of the classifiers. \n",
    "    The mean value of the best classifier is saved in a variable in order to compare it with the balanced data in task 7'''\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(name + \":\")\n",
    "    print(\"Mean Accuracy:\",result['mean_accuracy'])\n",
    "    print(\"Standard Devation Accuracy:\",result['std_accuracy'],\"\\n\")\n",
    "best_mean = results[\"Random Forest\"][\"mean_accuracy\"]\n",
    "if results[\"Linear Discriminant Analysis\"][\"mean_accuracy\"] > results[\"Random Forest\"][\"mean_accuracy\"]:\n",
    "    best_mean = results[\"Linear Discriminant Analysis\"][\"mean_accuracy\"]\n",
    "\n",
    "best_classifier = max(results, key=lambda k: results[k]['mean_accuracy'])\n",
    "print(f\"Best Classifier: {best_classifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the final model (RandomForestClassifier()): 0.6140\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.67      0.71      0.69       122\n",
      "           6       0.57      0.63      0.60       112\n",
      "           7       0.60      0.28      0.38        32\n",
      "           8       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61       272\n",
      "   macro avg       0.31      0.27      0.28       272\n",
      "weighted avg       0.61      0.61      0.60       272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\felea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\felea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\felea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\felea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\felea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "'''The best classifier is then used to fit the training data and predict the test data, then the accuracy of the model is calculated and printed. A classification report is also crated in order to view the results'''\n",
    "\n",
    "best_classifier = classifiers[best_classifier]  \n",
    "\n",
    "final_model = best_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred = best_classifier.predict(X_test_scaled) \n",
    "test_accuracy = final_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Test Accuracy of the final model ({best_classifier}): {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis:\n",
      "Mean Accuracy: 0.6063369963369963\n",
      "Standard Devation Accuracy: 0.0173326660531271 \n",
      "\n",
      "Random Forest:\n",
      "Mean Accuracy: 0.8237728937728938\n",
      "Standard Devation Accuracy: 0.010434675291684362 \n",
      "\n",
      "Best Classifier: Random Forest\n",
      "Test Accuracy of the final model (RandomForestClassifier()): 0.5625\n",
      "\n",
      "By balanceing the scaled train set the predict accuracy decreased by 0.05147058823529416\n",
      "By balanceing the scaled train set the predict accuracy improved by 0.23767256349878152\n"
     ]
    }
   ],
   "source": [
    "''' The data is run again but this time balanced using the SMOTE function from the imblearn library, then the data is fitted to the classifiers and the cross validation is performed again in order to determine the best classifier.\n",
    "    The results are stored in a dictionary and then compared with the previous results in order to determine if the balancing of the data improved the accuracy of the model'''\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "classifiers = {\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "cv = RepeatedKFold(n_splits=3, n_repeats=10, random_state=42)\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    scores = cross_val_score(clf, X_train_res, y_train_res, cv=cv, scoring='accuracy')\n",
    "    results[name] = {\n",
    "        \"mean_accuracy\": np.mean(scores),\n",
    "        \"std_accuracy\": np.std(scores)\n",
    "    }\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(name + \":\")\n",
    "    print(\"Mean Accuracy:\",result['mean_accuracy'])\n",
    "    print(\"Standard Devation Accuracy:\",result['std_accuracy'],\"\\n\")\n",
    "best_mean_res = results[\"Random Forest\"][\"mean_accuracy\"]\n",
    "if results[\"Linear Discriminant Analysis\"][\"mean_accuracy\"] > results[\"Random Forest\"][\"mean_accuracy\"]:\n",
    "    best_mean_res = results[\"Linear Discriminant Analysis\"][\"mean_accuracy\"]\n",
    "\n",
    "\n",
    "best_classifier = max(results, key=lambda k: results[k]['mean_accuracy'])\n",
    "print(f\"Best Classifier: {best_classifier}\")\n",
    "\n",
    "best_classifier = classifiers[best_classifier]  # Retrieve the classifier object\n",
    "\n",
    "final_model = best_classifier.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "test_accuracy_res = final_model.score(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy of the final model ({best_classifier}): {test_accuracy_res:.4f}\\n\")\n",
    "\n",
    "if test_accuracy_res > test_accuracy:\n",
    "    print(\"By balanceing the scaled train set the predict accuracy improved by\", test_accuracy_res - test_accuracy)\n",
    "else:\n",
    "    print(\"By balanceing the scaled train set the predict accuracy decreased by\", test_accuracy - test_accuracy_res)\n",
    "if best_mean_res > best_mean:\n",
    "    print(\"By balanceing the scaled train set the Mean Accuracy accuracy improved by\", best_mean_res - best_mean)\n",
    "else:\n",
    "    print(\"By balanceing the scaled train set the Mean Accuracy accuracy decreased by\", best_mean - best_mean_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
